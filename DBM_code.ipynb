{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone participated\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  \n",
    "import matplotlib.pyplot as plt\n",
    "import easygui as eg\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.ticker as mticker\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load brightspace files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone participated\n",
    "df1 = pd.read_excel('metaClean43Brightspace.xlsx')\n",
    "df2 = pd.read_excel('sales.xlsx')\n",
    "df3 = pd.read_excel('ExpertReviewsClean43LIWC.xlsx')\n",
    "df4 = pd.read_excel('UserReviewsClean43LIWC.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone participated, this is done to avoid going to the file loading process over and over agian while adjusting the code\n",
    "movies_df = df1.copy()\n",
    "sales_df = df2.copy()       \n",
    "cr_df = df3.copy()\n",
    "ur_df = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies file data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Jochem Vis\n",
    "\n",
    "# Drop not used columns\n",
    "movies_df.drop(columns=['studio', 'rating', 'runtime', 'cast', 'director', 'summary', 'awards'])\n",
    "\n",
    "# Add a movie_id column\n",
    "movies_df['movie_id'] = range(1, len(movies_df) + 1)\n",
    "\n",
    "# Rearrange the columns \n",
    "movies_df = movies_df[['movie_id', 'title', 'RelDate', 'genre', 'metascore', 'userscore', 'url']]\n",
    "\n",
    "# Drop duplicates\n",
    "movies_df = movies_df.drop_duplicates(subset='title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Jayshree Sharma\n",
    "\n",
    "# Drop not used columns\n",
    "sales_df = sales_df.drop(columns=[\"year\", \"release_date\", \"international_box_office\", \"domestic_box_office\", \"Unnamed: 8\", \"avg run per theatre\", \"runtime\", \"keywords\", \"creative_type\"])\n",
    "\n",
    "# Add a sales_id column\n",
    "sales_df[\"sales_id\"] = range(1, len(sales_df) +1)\n",
    "\n",
    "# Rearange the columns\n",
    "sales_df = sales_df[['sales_id', 'title', 'genre', 'url', 'worldwide_box_office', 'production_budget', 'opening_weekend', 'theatre_count']]\n",
    "\n",
    "# Drop duplicates\n",
    "sales_df = sales_df.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User review file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Daan van der Veldt\n",
    "\n",
    "# Drop duplicates\n",
    "ur_df.drop_duplicates(subset='Rev', inplace=True)\n",
    "\n",
    "# Drop not used columns\n",
    "ur_df = ur_df[['url', 'idvscore', 'dateP']]\n",
    "\n",
    "# Add a us_id column\n",
    "ur_df['ur_id'] = range(1, len(ur_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "ur_df = ur_df[['ur_id', 'url', 'idvscore', 'dateP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critical review file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Jelle Schelvis\n",
    "\n",
    "# Drop duplicates\n",
    "cr_df.drop_duplicates(subset='Rev', inplace=True)\n",
    "\n",
    "# Drop not used columns\n",
    "cr_df = cr_df[['url', 'idvscore', 'dateP']]\n",
    "\n",
    "# Add a us_id column\n",
    "cr_df['cr_id'] = range(1, len(cr_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "cr_df = cr_df[['cr_id', 'url', 'idvscore', 'dateP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of unique genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This by done by Daan van der Veldt\n",
    "\n",
    "# Merge the DataFrames including genre columns\n",
    "genre_df = movies_df.merge(sales_df, on='title', how='inner')\n",
    "\n",
    "# Drop not used columns\n",
    "genre_df = genre_df[['title', 'genre_x', 'genre_y']]\n",
    "\n",
    "# Split the 'genres' column by comma and create new columns for each genre\n",
    "split_genres = genre_df['genre_x'].str.split(',', expand=True)\n",
    "genre_df.loc[:, 'genre2'] = split_genres[0]\n",
    "genre_df.loc[:, 'genre3'] = split_genres[1]\n",
    "genre_df.loc[:, 'genre4'] = split_genres[2]\n",
    "genre_df.loc[:, 'genre5'] = split_genres[3]\n",
    "genre_df.loc[:, 'genre6'] = split_genres[4]\n",
    "genre_df.loc[:, 'genre7'] = split_genres[5]\n",
    "genre_df.loc[:, 'genre8'] = split_genres[6]\n",
    "genre_df.loc[:, 'genre9'] = split_genres[7]\n",
    "genre_df.loc[:, 'genre10'] = split_genres[8]\n",
    "genre_df.loc[:, 'genre11'] = split_genres[9]\n",
    "\n",
    "# Drop the split genre column and rename the first genre column\n",
    "genre_df = genre_df.drop(columns=['genre_x'])\n",
    "genre_df = genre_df.rename(columns={'genre_y': 'genre1'})\n",
    "\n",
    "# Check if the merged columns do not contain duplicate genre, if so delete the second occurance\n",
    "columns_to_check = ['genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10']\n",
    "for index, row in genre_df.iterrows():\n",
    "    genre1_value = row['genre1']\n",
    "    for col in columns_to_check:\n",
    "        if row[col] == genre1_value:\n",
    "            genre_df.at[index, col] = None \n",
    "\n",
    "# Concatenate the 'genre' columns into a single Series\n",
    "genre_series = genre_df[['genre1', 'genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10', 'genre11']].stack().reset_index(drop=True)\n",
    "\n",
    "# Get unique genre values and assign IDs\n",
    "unique_genres = genre_series.unique()\n",
    "genre_to_id = {genre: id for id, genre in enumerate(unique_genres)}\n",
    "\n",
    "# Create a DataFrame with genre IDs\n",
    "unique_genres_df = pd.DataFrame({'genre': unique_genres, 'genre_id': [genre_to_id[genre] for genre in unique_genres]})\n",
    "\n",
    "# Add a genre_id column\n",
    "unique_genres_df['genre_id'] = unique_genres_df['genre_id'] + 1\n",
    "\n",
    "# Rearrange the columns\n",
    "unique_genres_df = unique_genres_df[['genre_id', 'genre']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datafame of genres per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Daan van der Veldt\n",
    "\n",
    "# Merge the DataFrames including genre columns\n",
    "genre_rel_df = movies_df.merge(sales_df, on='title', how='inner')\n",
    "\n",
    "# Drop not used columns\n",
    "genre_rel_df = genre_rel_df[['title', 'genre_x', 'genre_y']]\n",
    "\n",
    "# Split the 'genres' column by comma and create new columns for each genre\n",
    "split_genres = genre_rel_df['genre_x'].str.split(',', expand=True)\n",
    "genre_rel_df.loc[:, 'genre2'] = split_genres[0]\n",
    "genre_rel_df.loc[:, 'genre3'] = split_genres[1]\n",
    "genre_rel_df.loc[:, 'genre4'] = split_genres[2]\n",
    "genre_rel_df.loc[:, 'genre5'] = split_genres[3]\n",
    "genre_rel_df.loc[:, 'genre6'] = split_genres[4]\n",
    "genre_rel_df.loc[:, 'genre7'] = split_genres[5]\n",
    "genre_rel_df.loc[:, 'genre8'] = split_genres[6]\n",
    "genre_rel_df.loc[:, 'genre9'] = split_genres[7]\n",
    "genre_rel_df.loc[:, 'genre10'] = split_genres[8]\n",
    "genre_rel_df.loc[:, 'genre11'] = split_genres[9]\n",
    "\n",
    "# Drop the split genre column and rename the first genre column\n",
    "genre_rel_df = genre_rel_df.drop(columns=['genre_x'])\n",
    "genre_rel_df = genre_rel_df.rename(columns={'genre_y': 'genre1'})\n",
    "\n",
    "# Check if the merged columns do not contain duplicate genre, if so delete the second occurance\n",
    "columns_to_check = ['genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10']\n",
    "for index, row in genre_rel_df.iterrows():\n",
    "    genre1_value = row['genre1']\n",
    "    for col in columns_to_check:\n",
    "        if row[col] == genre1_value:\n",
    "            genre_rel_df.at[index, col] = None \n",
    "\n",
    "# Concatenate the 'genre' columns into a single Series\n",
    "genre_series = genre_rel_df[['genre1', 'genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10', 'genre11']].stack().reset_index(drop=True)\n",
    "\n",
    "# Create a list of genres\n",
    "genre_columns = [f'genre{i}' for i in range(1, 12)]\n",
    "\n",
    "# Create a new column 'Combined_Genres' by combining genre columns into lists\n",
    "genre_rel_df['Combined_Genres'] = genre_rel_df.apply(lambda row: [row[col] for col in [f'genre{i}' for i in range(1, 12)] if pd.notna(row[col])], axis=1)\n",
    "\n",
    "# Drop the individual genre columns\n",
    "genre_rel_df.drop(columns=genre_columns, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "genre_rel_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Explode the 'Combined_Genres' column to create separate rows\n",
    "genre_rel_df = genre_rel_df.explode('Combined_Genres', ignore_index=True)\n",
    "\n",
    "# Reset the index\n",
    "genre_rel_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename column for merging\n",
    "genre_rel_df = genre_rel_df.rename(columns={'Combined_Genres': 'genre'})\n",
    "\n",
    "# Perform a left merge\n",
    "genre_rel_df = genre_rel_df.merge(unique_genres_df, on='genre', how='left')\n",
    "\n",
    "# Add a genre_rel_id column\n",
    "genre_rel_df['genre_rel_id'] = range(1, len(genre_rel_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "genre_rel_df = genre_rel_df[['genre_rel_id', 'genre_id', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge foreign keys to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by everyone, because everyone merged thei foreign key to the database they were responsible for\n",
    "\n",
    "# Merge foreign keys\n",
    "movies_df = movies_df.merge(sales_df[['title', 'sales_id']], on='title', how='left')\n",
    "sales_df = sales_df.merge(movies_df[['title', 'movie_id']], on='title', how='left')\n",
    "ur_df = ur_df.merge(movies_df[['url', 'movie_id']], on='url', how='left')\n",
    "cr_df = cr_df.merge(movies_df[['url', 'movie_id']], on='url', how='left')\n",
    "\n",
    "# Delete no longer needed column\n",
    "sales_df.drop(columns=['genre'], inplace=True)\n",
    "movies_df.drop(columns=['genre'], inplace=True)\n",
    "\n",
    "# Merge foerign key to genre relations and set up the data\n",
    "genre_rel_df = genre_rel_df.merge(movies_df[['title', 'movie_id']], on='title', how='left')\n",
    "genre_rel_df.drop(columns='title', inplace=True)\n",
    "genre_rel_df = genre_rel_df[['genre_rel_id', 'genre_id', 'movie_id']]\n",
    "\n",
    "# Drop some final unneeded columns\n",
    "movies_df.drop(columns='url', inplace=True)\n",
    "sales_df.drop(columns='title', inplace=True)\n",
    "sales_df.drop(columns='url', inplace=True)\n",
    "sales_df.drop(columns='opening_weekend', inplace=True)\n",
    "sales_df.drop(columns='theatre_count', inplace=True)\n",
    "ur_df.drop(columns='url', inplace=True)\n",
    "ur_df.drop(columns='dateP', inplace=True)\n",
    "cr_df.drop(columns='url', inplace=True)\n",
    "cr_df.drop(columns='dateP', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make database connection and delete all tables and create a SQLAlchemy engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Daan van der Veldt\n",
    "\n",
    "# Create a function to show the input dialog\n",
    "def get_db_connection_details():\n",
    "    msg = \"Enter Database Connection Details\"\n",
    "    title = \"Database Connection\"\n",
    "    field_names = [\"Host\", \"Database Name\", \"Username\", \"Password\"]\n",
    "    default_values = [\"localhost\", \"postgres\", \"myuser\", \"mypassword\"]\n",
    "\n",
    "    field_values = eg.multenterbox(msg, title, field_names, default_values)\n",
    "\n",
    "    # Check if the user canceled the input dialog\n",
    "    if field_values is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"host\": field_values[0],\n",
    "        \"database\": field_values[1],\n",
    "        \"user\": field_values[2],\n",
    "        \"password\": field_values[3]\n",
    "    }\n",
    "\n",
    "# Get database connection details from the user\n",
    "db_details = get_db_connection_details()\n",
    "\n",
    "if db_details is not None:\n",
    "    # Create a new connection\n",
    "    connection = psycopg2.connect(\n",
    "        host=db_details[\"host\"],\n",
    "        database=db_details[\"database\"],\n",
    "        user=db_details[\"user\"],\n",
    "        password=db_details[\"password\"]\n",
    "    )\n",
    "\n",
    "# Create cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Get a list of all table names in the current schema\n",
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\")\n",
    "\n",
    "table_names = [table[0] for table in cursor.fetchall()]\n",
    "\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name} CASCADE\")\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Create a SQLAlchemy engine using the obtained connection details\n",
    "engine = create_engine(f\"postgresql://{db_details['user']}:{db_details['password']}@{db_details['host']}/{db_details['database']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tables into SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is done by Daan van der Veldt\n",
    "\n",
    "# Import the movies data into SQL\n",
    "movies_df.to_sql('movies', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the sales data into SQL\n",
    "sales_df.to_sql('sales', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the user review data into SQL\n",
    "ur_df.to_sql('user_reviews', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the critical review data into SQL\n",
    "cr_df.to_sql('critical_reviews', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the unique genres data into SQL\n",
    "unique_genres_df.to_sql('unique_genres', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the genres relations data into SQL\n",
    "genre_rel_df.to_sql('genre_rel', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set primary keys and foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Daan van der Veldt\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "sql_command = \"\"\"\n",
    "    ALTER TABLE movies \n",
    "    ADD CONSTRAINT movie_id PRIMARY KEY (movie_id);\n",
    "\n",
    "    ALTER TABLE sales \n",
    "    ADD CONSTRAINT sales_id PRIMARY KEY (sales_id);\n",
    "\n",
    "    ALTER TABLE user_reviews \n",
    "    ADD CONSTRAINT ur_id PRIMARY KEY (ur_id);\n",
    "\n",
    "    ALTER TABLE critical_reviews \n",
    "    ADD CONSTRAINT cr_id PRIMARY KEY (cr_id);\n",
    "\n",
    "    ALTER TABLE genre_rel \n",
    "    ADD CONSTRAINT genre_rel_id PRIMARY KEY (genre_rel_id);\n",
    "\n",
    "    ALTER TABLE unique_genres \n",
    "    ADD CONSTRAINT genre_id PRIMARY KEY (genre_id);\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN sales_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE sales\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ALTER COLUMN genre_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE critical_reviews\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE user_reviews\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE movies \n",
    "    ADD CONSTRAINT fk_sales_id\n",
    "    FOREIGN KEY (sales_id) REFERENCES sales (sales_id);\n",
    "\n",
    "    ALTER TABLE sales \n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE user_reviews \n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE critical_reviews\n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ADD CONSTRAINT fk_genre_id\n",
    "    FOREIGN KEY (genre_id) REFERENCES unique_genres (genre_id);\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\"\"\"\n",
    "# Execute the SQL command\n",
    "cursor.execute(sql_command)\n",
    "\n",
    "# Commit the changes to the database\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change datatypes to match ERD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done by Jelle Schelvis\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql_command = \"\"\"\n",
    "    ALTER TABLE critical_reviews\n",
    "    ALTER COLUMN idvscore\n",
    "    SET DATA TYPE INT;\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN title \n",
    "    SET DATA TYPE VARCHAR(200);\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN metascore \n",
    "    SET DATA TYPE INT;\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN \"RelDate\"\n",
    "    SET DATA TYPE DATE;\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN metascore \n",
    "    SET DATA TYPE int;\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN userscore \n",
    "    SET DATA TYPE int;\n",
    "\n",
    "    ALTER TABLE unique_genres\n",
    "    ALTER COLUMN genre \n",
    "    SET DATA TYPE VARCHAR(30);\n",
    "\n",
    "    ALTER TABLE sales\n",
    "    ALTER COLUMN worldwide_box_office\n",
    "    SET DATA TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE sales\n",
    "    ALTER COLUMN production_budget\n",
    "    SET DATA TYPE INT;   \n",
    "\n",
    "    ALTER TABLE user_reviews\n",
    "    ALTER COLUMN idvscore\n",
    "    SET DATA TYPE int;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL command\n",
    "cursor.execute(sql_command)\n",
    "\n",
    "# Commit the changes to the database\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots for hypothesises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 7.6382\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# This is done by everyone, Jelle Schelvis created hypothesis 1 and 2, Daan van der Veldt created hypothesis 3 and 4, Jayshree Sharmma created hhypothesis 5 and 6, and Jochem Vis created hypothesis 7 and 8. The display screen coding was done by Daan van der Veldt.\n",
    "\n",
    "# Function to display a hypothesis plot based on the hypothesis number\n",
    "def display_hypothesis_plot(hypothesis_number):\n",
    "\n",
    "\n",
    "    if hypothesis_number == 1:\n",
    "\n",
    "        title = f'Hypothesis {hypothesis_number}: Expert reviews impact box office'\n",
    "        sql_command = \"\"\"\n",
    "        SELECT cr.movie_id, \n",
    "        ROUND(AVG(cr.idvscore)::numeric, 2) AS avg_idvscore,\n",
    "        ROUND(s.worldwide_box_office::numeric, 2) AS worldwide_box_office\n",
    "        FROM critical_reviews cr\n",
    "        INNER JOIN sales s ON s.movie_id = cr.movie_id\n",
    "        WHERE s.worldwide_box_office IS NOT NULL\n",
    "        AND cr.idvscore IS NOT NULL\n",
    "        GROUP BY cr.movie_id, s.worldwide_box_office;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        gemiddelde_idvscore = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "\n",
    "        pearson_corr, p_value = stats.pearsonr(gemiddelde_idvscore, worldwide_box_office)\n",
    "\n",
    "        slope, intercept = np.polyfit(gemiddelde_idvscore, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(gemiddelde_idvscore) + intercept\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0\n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_gemiddelde_idvscore = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_gemiddelde_idvscore.append(gemiddelde_idvscore[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        plt.ion()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.scatter(filtered_gemiddelde_idvscore, filtered_box_office, label=f'Hypothesis {hypothesis_number}', alpha=0.6, s=10)\n",
    "        ax.plot(gemiddelde_idvscore, trendline, color='red', label='Trendline')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'Expert Scores \\n(Pearson Correlation Coefficient: {pearson_corr:.4f}, Significance: {p_value:.4f})')        \n",
    "        ax.set_ylabel('Worldwide Box Office')\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        plt.show(block=False)\n",
    "\n",
    "        # pearson correlation analysis\n",
    "        print(f\"Pearson Correlation Coefficient: {pearson_corr:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    elif hypothesis_number == 2:\n",
    "        title = f'Hypothesis {hypothesis_number}: Expert reviews impact box office category drama'\n",
    "\n",
    "        sql_command = \"\"\"\n",
    "        SELECT cr.movie_id, \n",
    "        ROUND(AVG(cr.idvscore)::numeric, 2) AS avg_idvscore,\n",
    "        ROUND(s.worldwide_box_office::numeric, 2) AS worldwide_box_office\n",
    "        FROM critical_reviews cr\n",
    "        INNER JOIN sales s ON s.movie_id = cr.movie_id AND s.worldwide_box_office IS NOT NULL\n",
    "        INNER JOIN genre_rel gr ON gr.movie_id = cr.movie_id\n",
    "        INNER JOIN unique_genres ug ON ug.genre_id = gr.genre_id\n",
    "        GROUP BY cr.movie_id, s.worldwide_box_office, ug.genre\n",
    "        HAVING AVG(cr.idvscore) IS NOT NULL\n",
    "        AND ug.genre = 'Drama';\n",
    "        ;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        gemiddelde_idvscore = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "\n",
    "        pearson_corr, p_value = stats.pearsonr(gemiddelde_idvscore, worldwide_box_office)\n",
    "\n",
    "        slope, intercept = np.polyfit(gemiddelde_idvscore, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(gemiddelde_idvscore) + intercept\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0 \n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_gemiddelde_idvscore = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_gemiddelde_idvscore.append(gemiddelde_idvscore[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        plt.ion()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.scatter(filtered_gemiddelde_idvscore, filtered_box_office, label=f'Hypothesis {hypothesis_number}', alpha=0.6, s=10)\n",
    "        ax.plot(gemiddelde_idvscore, trendline, color='red', label='Trendline')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'Expert Scores \\n(Pearson Correlation Coefficient: {pearson_corr:.4f}, Significance: {p_value:.4f})')        \n",
    "        ax.set_ylabel('Worldwide Box Office')\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "    elif hypothesis_number == 3:\n",
    "        title = f'Hypothesis {hypothesis_number}: Negative user scores and box office'\n",
    "        \n",
    "        # Select SQL query and use data\n",
    "        sql_command = \"\"\"\n",
    "            SELECT ur.movie_id, AVG(ur.idvscore) AS avg_idvscore, s.worldwide_box_office\n",
    "            FROM user_reviews ur\n",
    "            INNER JOIN sales s ON s.movie_id = ur.movie_id\n",
    "            WHERE s.worldwide_box_office IS NOT NULL\n",
    "            GROUP BY ur.movie_id, s.worldwide_box_office;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        userscores = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "        slope, intercept = np.polyfit(userscores, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(userscores) + intercept\n",
    "\n",
    "        pearson_corr, p_value = stats.pearsonr(userscores, worldwide_box_office)\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0 \n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_userscores = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_userscores.append(userscores[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        # Create a plot\n",
    "        plt.ion()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Make the main plot\n",
    "        ax.scatter(filtered_userscores, filtered_box_office, label=f'Hypothesis {hypothesis_number}', alpha=0.6, s=5)\n",
    "        ax.plot(userscores, trendline, color='red', label='Trendline')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'User Scores \\n (Pearson Correlation Coefficient: {pearson_corr:.4f}, Significance: {p_value:.4f})')\n",
    "        ax.set_ylabel('Worldwide Box Office')\n",
    "        ax.legend()\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax.grid(True)\n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "    elif hypothesis_number == 4:\n",
    "        title = f'Hypothesis {hypothesis_number}: User reviews and box office'\n",
    "\n",
    "        # Select SQL query and use that data\n",
    "        sql_command = \"\"\"\n",
    "            SELECT ur.movie_id,\n",
    "            COUNT(ur.ur_id) AS user_review_count,\n",
    "            s.worldwide_box_office\n",
    "            FROM user_reviews ur\n",
    "            INNER JOIN sales s ON s.movie_id = ur.movie_id\n",
    "            WHERE s.worldwide_box_office IS NOT NULL\n",
    "            GROUP BY ur.movie_id, s.worldwide_box_office;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        user_review_count = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "\n",
    "        pearson_corr, p_value = stats.pearsonr(user_review_count, worldwide_box_office)\n",
    "\n",
    "        # Create trendline\n",
    "        slope, intercept = np.polyfit(user_review_count, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(user_review_count) + intercept\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0  \n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_user_review_count = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_user_review_count.append(user_review_count[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        y_min = min(filtered_box_office)\n",
    "        y_max = max(filtered_box_office)\n",
    "\n",
    "\n",
    "        # Create the main plot and the zoomed-in subplot within the same figure\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6)) \n",
    "\n",
    "        # Make the main plot\n",
    "        ax[0].scatter(filtered_user_review_count, filtered_box_office, label='Main Plot', alpha=0.6, s=10)\n",
    "        ax[0].plot(user_review_count, trendline, color='red', label='Trendline')\n",
    "        ax[0].set_title(title)\n",
    "        ax[0].set_xlabel(f'User Score Count per movie \\n (Pearson Correlation Coefficient: {pearson_corr:.4f}, Significance: {p_value:.4f})')\n",
    "        ax[0].set_ylabel('Worldwide Box Office (in millions)')  \n",
    "        ax[0].set_xlim(0, 1000)\n",
    "        ax[0].set_ylim(y_min, y_max)  \n",
    "\n",
    "        # Format the y-axis tick labels to display values in millions\n",
    "        ax[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax[0].legend()\n",
    "        ax[0].grid(True)\n",
    "\n",
    "        # Create the zoomed-in subplot\n",
    "        ax[1].scatter(filtered_user_review_count, filtered_box_office, alpha=0.6, s=1)\n",
    "        ax[1].plot(user_review_count, trendline, color='red')\n",
    "        ax[1].set_title('Zoomed in fist grid')\n",
    "        ax[1].set_xlabel('User Score Count per movie')\n",
    "        ax[1].set_ylabel('Worldwide Box Office (in millions)') \n",
    "        ax[1].set_xlim(0, 200)  \n",
    "        ax[1].set_ylim(0, 200000000)  \n",
    "\n",
    "        # Format the y-axis tick labels to display values in millions\n",
    "        ax[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax[1].grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    elif hypothesis_number == 5:\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie release in holdiday season'\n",
    "\n",
    "        # Select SQL query and use that data for the ANOVA test\n",
    "        sql_command = \"\"\"\n",
    "        SELECT\n",
    "        (CASE WHEN EXTRACT(MONTH FROM \"RelDate\") = 12 THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_christmas,\n",
    "        (\"worldwide_box_office\") AS average_worldwide_box_office,\n",
    "        (CASE WHEN EXTRACT(MONTH FROM \"RelDate\") BETWEEN 6 AND 9  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_summer,\n",
    "        (CASE WHEN EXTRACT(MONTH FROM \"RelDate\") IN (1,2,3,4,5,10,11)  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_outsideholiday\n",
    "        FROM sales\n",
    "            INNER JOIN movies ON movies.movie_ID = sales.movie_ID;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    " \n",
    "        # Extract the required columns for the ANOVA test\n",
    "        christmas_data = [column[1] for column in data if column[1] is not None]\n",
    "        summer_data = [column[2] for column in data if column[2] is not None]\n",
    "        overall_data = [column[0] for column in data if column[0] is not None]\n",
    "        outside_holiday_data = [column[3] for column in data if column[3] is not None]\n",
    "\n",
    "        # Perform the ANOVA test\n",
    "        f_statistic, p_value = f_oneway(christmas_data, summer_data, overall_data, outside_holiday_data)\n",
    "\n",
    "        # Output the results\n",
    "        print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "        # Select SQL query and use that data for the chart\n",
    "        sql_command = \"\"\" \n",
    "            SELECT\n",
    "            AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") = 12 THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_christmas,\n",
    "            AVG(\"worldwide_box_office\") AS average_worldwide_box_office,\n",
    "            AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") BETWEEN 6 AND 9  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_summer,\n",
    "            AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") IN (1,2,3,4,5,10,11)  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_outsideholiday\n",
    "            FROM sales\n",
    "                INNER JOIN movies ON movies.movie_ID = sales.movie_ID\n",
    "         \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    " \n",
    "        # Create variable season\n",
    "        season = ['overall', 'christmas', 'summer']\n",
    "        \n",
    "        # Extract individual float values from the data\n",
    "        box_office_overall = [float(column[0]) for column in data]\n",
    "        box_office_christmas = [float(column[1]) for column in data]\n",
    "        box_office_summer = [float(column[2]) for column in data]\n",
    "                \n",
    "        x_positions = range(len(season))\n",
    "    \n",
    "        # Create bar charts for each season\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.bar(season[1], box_office_christmas, color='magenta', label='Christmas')\n",
    "        ax.bar(season[0], box_office_overall, color='lightgreen', label='Overall')\n",
    "        ax.bar(season[2], box_office_summer, color='cyan', label='Summer')\n",
    "                \n",
    "        ax.set_xticks(x_positions, season)\n",
    "        ax.set_xlabel(f'Release Season \\n (\"F-statistic: {f_statistic:.4f}\", \"P-value: {p_value:.4f}\" )')\n",
    "        ax.set_ylabel('Box_Office')\n",
    "        ax.set_title('Box_office per Season')\n",
    "        ax.grid(True)\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        plt.show()\n",
    "\n",
    "    elif hypothesis_number == 6:\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie release outside holiday season'\n",
    "\n",
    "        # Select SQL query and use that data for the chart \n",
    "        sql_command = \"\"\" \n",
    "            SELECT\n",
    " \t        AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") = 12 THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_christmas,\n",
    "  \t        AVG(\"worldwide_box_office\") AS average_worldwide_box_office,\n",
    "  \t        AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") BETWEEN 6 AND 9  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_summer,\n",
    "\t        AVG(CASE WHEN EXTRACT(MONTH FROM \"RelDate\") IN (1,2,3,4,5,10,11)  THEN \"worldwide_box_office\" ELSE NULL END) AS average_worldwide_box_office_outsideholiday\n",
    "            FROM sales\n",
    "            INNER JOIN movies ON movies.movie_ID = sales.movie_ID;\n",
    "         \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        \n",
    "        # Create variable season\n",
    "        season = ['overall', 'outside_holiday']\n",
    "      \n",
    "        # Extract individual float values from the data\n",
    "        box_office_overall = [float(column[1]) for column in data]\n",
    "        box_office_outsideholiday = [float(column[3]) for column in data]\n",
    "\n",
    "        x_positions = range(len(season))\n",
    "\n",
    "        # Create bar charts for each season\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.bar(season[0], box_office_overall, color='blue', label='Overall')\n",
    "        ax.bar(season[1], box_office_outsideholiday, color='cyan', label='Outside Holiday')\n",
    "\n",
    "        ax.set_xticks(x_positions, season)\n",
    "        ax.set_xlabel('Release Season')\n",
    "        ax.set_ylabel('Box_Office')\n",
    "        ax.set_title('Box_office per Season')\n",
    "        ax.grid(True)\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        plt.show()\n",
    "\n",
    "    elif hypothesis_number == 7:\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie budget and box office'\n",
    "\n",
    "        # Select SQL query and use that data for the ANOVA test\n",
    "        sql_command = \"\"\"\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN production_budget IS NULL THEN 'Unknown'\n",
    "                    WHEN production_budget < 1000000 THEN 'Very Low Budget'\n",
    "                    WHEN production_budget >= 1000000 AND production_budget < 5000000 THEN 'Low Budget'\n",
    "                    WHEN production_budget >= 5000000 AND production_budget < 10000000 THEN 'Medium-Low Budget'\n",
    "                    WHEN production_budget >= 10000000 AND production_budget < 30000000 THEN 'Medium Budget'\n",
    "                    WHEN production_budget >= 30000000 AND production_budget < 70000000 THEN 'Medium-High Budget'\n",
    "                    WHEN production_budget >= 70000000 AND production_budget < 100000000 THEN 'High-Medium Budget'\n",
    "                    WHEN production_budget >= 100000000 THEN 'High Budget'\n",
    "                END AS Budget_Category,\n",
    "                worldwide_box_office AS Average_Box_Office_Sales\n",
    "            FROM\n",
    "                sales\n",
    "            WHERE\n",
    "                production_budget IS NOT NULL\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the modified SQL query to retrieve data\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "\n",
    "        # Create a DataFrame with the retrieved data\n",
    "        sales_df = pd.DataFrame(data, columns=['budget_category', 'average_box_office_Sales'])\n",
    "\n",
    "        # Fit the ANOVA model\n",
    "        model = ols('average_box_office_Sales ~ C(budget_category)', data=sales_df).fit()\n",
    "\n",
    "        # Perform ANOVA\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "       # Select the F-statistic and the p-value from the ANOVA table\n",
    "        f_statistic = anova_table.loc['C(budget_category)', 'F']\n",
    "        p_value = anova_table.loc['C(budget_category)', 'PR(>F)']\n",
    "\n",
    "        # Print the F-statistic and the p-value\n",
    "        print(f\"F-statistic : {f_statistic}\")\n",
    "        print(f\"P-value : {p_value}\")\n",
    "\n",
    "        # Select SQL query and use that data\n",
    "        sql_command = \"\"\"\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN production_budget IS NULL THEN 'Unknown'\n",
    "                    WHEN production_budget < 1000000 THEN 'Very Low Budget'\n",
    "                    WHEN production_budget >= 1000000 AND production_budget < 5000000 THEN 'Low Budget'\n",
    "                    WHEN production_budget >= 5000000 AND production_budget < 10000000 THEN 'Medium-Low Budget'\n",
    "                    WHEN production_budget >= 10000000 AND production_budget < 30000000 THEN 'Medium Budget'\n",
    "                    WHEN production_budget >= 30000000 AND production_budget < 70000000 THEN 'Medium-High Budget'\n",
    "                    WHEN production_budget >= 70000000 AND production_budget < 100000000 THEN 'High-Medium Budget'\n",
    "                    WHEN production_budget >= 100000000 THEN 'High Budget'\n",
    "                END AS Budget_Category,\n",
    "                AVG(worldwide_box_office) AS Average_Box_Office_Sales\n",
    "            FROM\n",
    "                sales\n",
    "            WHERE\n",
    "                production_budget IS NOT NULL\n",
    "            GROUP BY\n",
    "                Budget_Category\n",
    "            ORDER BY\n",
    "                Average_Box_Office_Sales DESC;\n",
    "            \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        budget_category = [(column[0]) for column in data]\n",
    "        average_box_office_sales = [(column[1]) for column in data]\n",
    "\n",
    "        # Make the plot\n",
    "        fig, ax = plt.subplots(figsize=(13, 8))\n",
    "        ax.bar(budget_category, average_box_office_sales, color='lightgreen')\n",
    "        ax.set_xlabel('Budget Category')\n",
    "        ax.set_ylabel('Average Box Office Sales (in millions)')\n",
    "        ax.set_title('Average Box Office Sales per Budget Category')\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # Add the F-value and p-value to the plot\n",
    "        plt.text(0.95, -0.1, f'F-value: {f_statistic:.2f}', transform=ax.transAxes, fontsize=12, ha='right')\n",
    "        plt.text(0.95, -0.15, f'P-value: {p_value:.4f}', transform=ax.transAxes, fontsize=12, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "    elif hypothesis_number == 8:\n",
    "        title = f'Hypothesis {hypothesis_number}: Genres and box office sales'\n",
    "        \n",
    "        # Select SQL query and use that data\n",
    "        sql_command = \"\"\" \n",
    "                SELECT g.Genre, AVG(s.worldwide_box_office) AS avg_sales\n",
    "                FROM genre_rel AS gr\n",
    "                JOIN sales AS s ON gr.movie_id = s.sales_id\n",
    "                JOIN unique_genres AS g ON gr.genre_id = g.Genre_ID\n",
    "                GROUP BY g.Genre\n",
    "                ORDER BY avg_sales DESC;\n",
    "            \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        genre = [(colum[0]) for colum in data]\n",
    "        worldwide_box_office = [(colum[1]) for colum in data]\n",
    "\n",
    "        # Make the plot\n",
    "        fig, ax = plt.subplots(figsize=(17, 8))\n",
    "        ax.bar(genre, worldwide_box_office, color='skyblue')\n",
    "        ax.set_xlabel('Genres')\n",
    "        ax.set_ylabel('Box Office Sales (in millions)')\n",
    "        ax.set_title('Box Office Sales per Genre')\n",
    "        ax.set_xticks(range(len(genre)))\n",
    "        ax.set_xticklabels(genre, rotation=45)   \n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{x / 1e6:.0f}M'))\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "# Create a function to show the hypothesis selection dialog\n",
    "def select_hypothesis_plot():\n",
    "    while True:\n",
    "        msg = \"Select a Hypothesis Plot to Display\"\n",
    "        title = \"Hypothesis Selection\"\n",
    "        choices = [\n",
    "            \"Hypothesis 1: Expert reviews impact box office\",\n",
    "            \"Hypothesis 2: Expert reviews influence drama movies\",\n",
    "            \"Hypothesis 3: Negative user scores and box office\",\n",
    "            \"Hypothesis 4: User reviews and box office\",\n",
    "            \"Hypothesis 5: Movie release timing\",\n",
    "            \"Hypothesis 6: Movie release outside holiday season\",\n",
    "            \"Hypothesis 7: Movie budget and box office\",\n",
    "            \"Hypothesis 8: Genres and box office sales\",\n",
    "            \"Exit\"\n",
    "        ]\n",
    "\n",
    "        choice = eg.choicebox(msg, title, choices=choices)\n",
    "\n",
    "        if choice is None or choice == \"Exit\":\n",
    "            break\n",
    "\n",
    "        # Extract the hypothesis number\n",
    "        hypothesis_number = int(choice.split(\":\")[0].split()[-1])\n",
    "        display_hypothesis_plot(hypothesis_number)\n",
    "\n",
    "# Show the hypothesis selection dialog\n",
    "select_hypothesis_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
